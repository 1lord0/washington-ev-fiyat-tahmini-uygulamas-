pip install scikit-learn
pip install pandas
pip install numpy



import pandas as pd

import numpy as np
df=pd.read_csv(r"C:\Users\eren\Desktop\makine sadi evren sc\archive_3\data.csv")

import sys
df.drop(["date","country","statezip","street"],axis=1,inplace=True)


df[df["city"]=="Kent"]
import numpy as np
df["ev_yenilendi_mi"] = df["yr_renovated"].apply(lambda x: 1 if x > 0 else 0)
city_counts = df['city'].value_counts()
  # Åehirdeki veri sayÄ±sÄ±nÄ± hesapla
low_population_cities = city_counts[city_counts < 100].index  # 100'den az olanlarÄ± belirle
df = df[~df['city'].isin(low_population_cities)]  # Bu ÅŸehirleri Ã§Ä±kar

print(f"âœ… GÃ¼ncellenmiÅŸ veri setinde {df['city'].nunique()} farklÄ± ÅŸehir kaldÄ±.")


df["ev_yili"]=df.apply(lambda row: row["yr_built"] if row["yr_renovated"]==0  else row["yr_renovated"],axis=1)


df=df.drop(["yr_built","yr_renovated"],axis=1)




# 'price' sÃ¼tunundaki 'e' karakterlerini sayÄ±sal deÄŸere Ã§evirme
df['price'] = df['price'].apply(lambda x: int(float(x)))

df=df[~(df["city"]=="Kent")]










from sklearn.model_selection import train_test_split
#gridsearch ile hangi ÅŸehre hangi parametreleri seÃ§meliyiz bunu bir sÃ¶zlÃ¼ÄŸe aktarÄ±yoruz
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import ElasticNet



df = df[~df['city'].isin(df['city'].value_counts()[df['city'].value_counts() < 100].index)]


[ df.drop(i,axis=0,inplace=True) for i in df['city'].value_counts() if i<100 ]

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import ElasticNet

best_params_by_city = {}

for city in df['city'].unique():
    df_city = df[df['city'] == city]
    n_samples = len(df_city)  # O ÅŸehirdeki veri sayÄ±sÄ±

    if n_samples < 2:
        print(f"Yetersiz veri nedeniyle {city} atlandÄ±.")
        continue  

    print(f"Åehir: {city}")

    X = df_city.drop(columns=['price', 'city'])  
    y = df_city['price']  

    if n_samples < 10:
        X_train, y_train = X, y
        X_test, y_test = X, y
    else:
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    param_grid = {
        'alpha': np.logspace(-4, 1, 10),  
        'l1_ratio': np.linspace(0, 1, 10)  
    }

    # Veri sayÄ±sÄ±na gÃ¶re `cv` deÄŸerini ayarla
    cv_value = min(3, n_samples)  # Ã–rnek sayÄ±sÄ±ndan bÃ¼yÃ¼k olamaz

    model = ElasticNet()
    
    # EÄŸer veri sayÄ±sÄ± 1 ise GridSearch kullanmadan modeli eÄŸit
    if n_samples == 1:
        model.fit(X_train, y_train)
        best_params = {'alpha': model.alpha, 'l1_ratio': model.l1_ratio}
    else:
        grid_search = GridSearchCV(model, param_grid, cv=cv_value, scoring='neg_mean_squared_error')
        grid_search.fit(X_train, y_train)
        best_params = grid_search.best_params_

    best_params_by_city[city] = best_params
    print(f"Åehir: {city}, En iyi parametreler: {best_params}")

print("\nTÃ¼m ÅŸehirler iÃ§in en iyi parametreler:")
print(best_params_by_city)




from sklearn.linear_model import ElasticNet
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


predictions_by_city = {}



for city in df['city'].unique():
    df_city = df[df['city'] == city]
    n_samples = len(df_city)

    if city not in best_params_by_city or n_samples < 2:
        print(f"Yetersiz veri nedeniyle {city} atlandÄ±.")
        continue  

    print(f"\nÅehir: {city} iÃ§in model eÄŸitiliyor...")

    X = df_city.drop(columns=['price', 'city'])  
    y = df_city['price']  

    if n_samples < 10:
        X_train, y_train = X, y
        X_test, y_test = X, y
    else:
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # En iyi parametreleri al
    best_params = best_params_by_city[city]

    # Modeli en iyi parametrelerle eÄŸit
    model = ElasticNet(alpha=best_params['alpha'], l1_ratio=best_params['l1_ratio'])
    model.fit(X_train, y_train)

    # Tahmin yap
    y_pred = model.predict(X_test)

    # Hata hesapla
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)  # R^2 deÄŸeri hesaplama
    
    # SonuÃ§larÄ± sakla
    predictions_by_city[city] = {
        'GerÃ§ek DeÄŸerler': y_test.values,
        'Tahminler': y_pred,
        'MAE': mae,
        'MSE': mse,
        'R2': r2
    }

    print(f"{city} iÃ§in eÄŸitim tamamlandÄ±. MAE: {mae:.2f}, MSE: {mse:.2f}, RÂ²: {r2:.2f}")

# Tahmin sonuÃ§larÄ±nÄ± gÃ¶ster
print("\nğŸ“Š TÃ¼m ÅŸehirler iÃ§in tahmin sonuÃ§larÄ±:")
for city, results in predictions_by_city.items():
    print(f"\nğŸ™ Åehir: {city}")
    print(f"ğŸ“Œ GerÃ§ek: {results['GerÃ§ek DeÄŸerler'][:5]}")
    print(f"ğŸ”® Tahmin: {results['Tahminler'][:5]}")
    print(f"ğŸ“‰ MAE: {results['MAE']:.2f}")
    print(f"ğŸ“Š MSE: {results['MSE']:.2f}")
    print(f"ğŸ“ˆ RÂ²: {results['R2']:.2f}")


import pickle






import streamlit as st
import joblib
import numpy as np
import pandas as pd






import joblib

import joblib

import joblib
import os

# Modellerin kaydedileceÄŸi klasÃ¶rÃ¼ belirle
save_dir = "C:\\Users\\eren\\Desktop\\model_deploy"
os.makedirs(save_dir, exist_ok=True)  # KlasÃ¶r yoksa oluÅŸtur

# Her ÅŸehir iÃ§in modeli kaydet
for city, model in best_params_by_city.items():
    file_path = os.path.join(save_dir, f"{city.lower()}_model.pkl")  # Dosya yolunu oluÅŸtur
    joblib.dump(model, file_path)
    print(f"{file_path} dosyasÄ±na kaydedildi!")





import streamlit as st
import numpy as np
import joblib  # Modelinizi yÃ¼klemek iÃ§in

# KullanÄ±cÄ±ya hangi modeli kullanacaÄŸÄ± sorulacak
model_secimi = st.sidebar.selectbox("Kullanmak Ä°stediÄŸiniz Modeli SeÃ§in", ["Model 1", "Model 2", "Model 3"])

# Modeli yÃ¼kleme (seÃ§ilen modele gÃ¶re)
if model_secimi == "Model 1":
    model = joblib.load('model_1.pkl')
elif model_secimi == "Model 2":
    model = joblib.load('model_2.pkl')
elif model_secimi == "Model 3":
    model = joblib.load('model_3.pkl')

# Åehir listesi
sehirler = ['Washington', 'New York', 'Los Angeles', 'Chicago', 'Miami']

# KullanÄ±cÄ±dan girdileri alma
st.sidebar.header("Ev Ã–zelliklerini Girin")

# Ã–rnek girdiler
metrekare = st.sidebar.number_input("Metrekare (mÂ²)", min_value=50, max_value=500, value=100)
oda_sayisi = st.sidebar.number_input("Oda SayÄ±sÄ±", min_value=1, max_value=10, value=3)
bina_yasi = st.sidebar.number_input("Bina YaÅŸÄ±", min_value=0, max_value=100, value=10)

# Åehir seÃ§imi
sehir = st.sidebar.selectbox("Åehir", sehirler)

# Åehri sayÄ±sal deÄŸere dÃ¶nÃ¼ÅŸtÃ¼rme
sehir_mapping = {sehir: idx for idx, sehir in enumerate(sehirler)}
sehir_encoded = sehir_mapping[sehir]

# Tahmin yapma butonu
if st.sidebar.button("Tahmin Yap"):
    # KullanÄ±cÄ± girdilerini modele uygun formata dÃ¶nÃ¼ÅŸtÃ¼rme
    input_data = np.array([[metrekare, oda_sayisi, bina_yasi, sehir_encoded]])
    
    # Tahmin yapma
    tahmin = model.predict(input_data)
    
    # Sonucu ekrana yazdÄ±rma
    st.success(f"Tahmini Ev FiyatÄ±: {tahmin[0]:.2f} TL")




























"""





# Streamlit uygulamasÄ±nÄ±n baÅŸlÄ±ÄŸÄ±
st.title("ğŸ  Ev Fiyat Tahmin UygulamasÄ±")
st.write("Bu uygulama, Elastic Net modeli kullanarak ev fiyatlarÄ±nÄ± tahmin eder.")

# Modeli yÃ¼kleme
model = joblib.load('C:\\Users\\eren\\Desktop\\model_deploy\\ev_fiyat_modeli.pkl    ')

# Åehir listesi (veri setinizdeki ÅŸehirler)
sehirler = [
    "Seattle", "Renton", "Bellevue", "Redmond", "Issaquah", "Kirkland", "Kent", 
    "Auburn", "Sammamish", "Federal Way", ""Shoreline", "Woodinville"
]



"if sehir == "Seattle":
    model = joblib.load('C:\\Users\\eren\\Desktop\\model_deploy\\seattle_model.pkl')
elif sehir == "Renton":
    model = joblib.load('C:\\Users\\eren\\Desktop\\model_deploy\\renton_model.pkl')
elif sehir == "Bellevue":
    model = joblib.load('C:\\Users\\eren\\Desktop\\model_deploy\\bellevue_model.pkl')


# KullanÄ±cÄ±dan girdileri alma
st.sidebar.header("Ev Ã–zelliklerini Girin")

# Ã–rnek girdiler
metrekare = st.sidebar.number_input("Metrekare (mÂ²)", min_value=50, max_value=500, value=100)
oda_sayisi = st.sidebar.number_input("Oda SayÄ±sÄ±", min_value=1, max_value=10, value=3)
bina_yasi = st.sidebar.number_input("Bina YaÅŸÄ±", min_value=0, max_value=100, value=10)

# Åehir seÃ§imi
sehir = st.sidebar.selectbox("Åehir", sehirler)

# Åehri sayÄ±sal deÄŸere dÃ¶nÃ¼ÅŸtÃ¼rme
sehir_mapping = {sehir: idx for idx, sehir in enumerate(sehirler)}
sehir_encoded = sehir_mapping[sehir]

# Tahmin yapma butonu
if st.sidebar.button("Tahmin Yap"):
    # KullanÄ±cÄ± girdilerini modele uygun formata dÃ¶nÃ¼ÅŸtÃ¼rme
    input_data = np.array([[metrekare, oda_sayisi, bina_yasi, sehir_encoded]])
    
    # Tahmin yapma
    tahmin = model.predict(input_data)
    
    # Sonucu ekrana yazdÄ±rma
    st.success(f"Tahmini Ev FiyatÄ±: {tahmin[0]:.2f} TL")""
"""





